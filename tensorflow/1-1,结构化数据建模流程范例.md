# 1-1,结构化数据建模流程范例


### 一，准备数据


titanic数据集的目标是根据乘客信息预测他们在Titanic号撞击冰山沉没后能否生存。

结构化数据一般会使用Pandas中的DataFrame进行预处理。

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import models,layers
```

```python
dftrain_raw  = pd.read_csv("./data/titanic/train.csv")
dftest_raw  = pd.read_csv("./data/titanic/test.csv")
```

```python
dftrain_raw .head(10)
```

存活分布情况

```python
%matplotlib inline
%config InlineBackend.figure_format="png"
ax = dftrain_raw["Survived"].value_counts().plot(kind="bar",rot=0)
ax.set_ylabel("counts")
ax.set_xlabel("Survived")
plt.show()
```

年龄分布情况

```python
%matplotlib inline
%config InlineBackend.figure_format="png"
ax = dftrain_raw["Age"].plot(kind="hist",bins=20)
ax.set_ylabel("counts")
ax.set_xlabel("age")
plt.show()
```

```python
%matplotlib inline
%config InlineBackend.figure_format="png"
ax01 = dftrain_raw.query('Survived == 1')['Age'].plot(kind="density",label="Survived==1")
ax02 = dftrain_raw.query('Survived == 0')['Age'].plot(kind="density",label="Survived==0")
plt.xlabel("age")
plt.ylabel("density")
plt.legend()
```

### 二，特征工程

```python
def preprocessing(dfdata):
    dfresult = pd.DataFrame()
    
    #Pclass 
    dfPclass = pd.get_dummies(dfdata['Pclass'])
    dfPclass.columns = ['Pclass_' +str(x) for x in dfPclass.columns ]
    dfresult = pd.concat([dfresult,dfPclass],axis = 1)

    #Sex
    dfSex = pd.get_dummies(dfdata['Sex'])
    dfresult = pd.concat([dfresult,dfSex],axis = 1)

    #Age
    dfresult['Age'] = dfdata['Age'].fillna(0)
    dfresult['Age_null'] = pd.isna(dfdata['Age']).astype('int32')

    #SibSp,Parch,Fare
    dfresult['SibSp'] = dfdata['SibSp']
    dfresult['Parch'] = dfdata['Parch']
    dfresult['Fare'] = dfdata['Fare']

    #Carbin
    dfresult['Cabin_null'] =  pd.isna(dfdata['Cabin']).astype('int32')

    #Embarked
    dfEmbarked = pd.get_dummies(dfdata['Embarked'],dummy_na=True)
    dfEmbarked.columns = ['Embarked_' + str(x) for x in dfEmbarked.columns]
    dfresult = pd.concat([dfresult,dfEmbarked],axis = 1)
    return(dfresult)
```

```python
x_train = preprocessing(dftrain_raw)
y_train = dftrain_raw['Survived']

x_test = preprocessing(dftest_raw)
y_test = dftest_raw['Survived']
print("x_train.shape =", x_train.shape)
print("x_test.shape =", x_test.shape)
```

### 二，定义模型


使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。

此处选择使用最简单的Sequential，按层顺序模型。

```python
# tf.keras.backend.clear_session()
model = models.Sequential()
model.add(layers.Dense(20,activation = 'relu',input_shape=(15,)))
model.add(layers.Dense(10,activation = 'relu' ))
model.add(layers.Dense(1,activation = 'sigmoid' ))

model.summary()
```




### 三、训练模型

```python
# 二分类问题选择二元交叉熵损失函数
model.compile(optimizer='adam',
            loss='binary_crossentropy',
            metrics=['AUC'])

history = model.fit(x_train,y_train,
                    batch_size= 64,
                    epochs= 30,
                    validation_split=0.2 #分割一部分训练数据用于验证
                   )
```

### 四、评估模型

```python
%matplotlib inline
%config InlineBackend.figure_format="svg"
def plot_metric(history, metric):
    train_metrics = history.history[metric]
    val_metrics = history.history['val_'+metric]
    epochs = range(1, len(train_metrics) + 1)
    plt.plot(epochs, train_metrics, 'bo--')
    plt.plot(epochs, val_metrics, 'ro-')
    plt.title('Training and validation '+ metric)
    plt.xlabel("Epochs")
    plt.ylabel(metric)
    plt.legend(["train_"+metric, 'val_'+metric])
    plt.show()
```

```python
plot_metric(history,"loss")
```

```python
plot_metric(history,"AUC")
```

我们再看一下模型在测试集上的效果

```python
model.evaluate(x_test,y_test)
```

### 五、使用模型


预测概率

```python
model.predict(x_test[:10])
```

预测类别

```python
model.predict_classes(x_test[0:10])
```

### 六、保存模型

```python
# 保存权重，该方式仅仅保存权重张量
model.save_weights('./data/tf_model_weights.ckpt',save_format = "tf")
```

```python
# 保存模型结构与模型参数到文件,该方式保存的模型具有跨平台性便于部署
model.save('./data/tf_model_savedmodel', save_format="tf")
print('export saved model.')
# del model
```

```python
model_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel')
model_loaded.evaluate(x_test,y_test)
```
