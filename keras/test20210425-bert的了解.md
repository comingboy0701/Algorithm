## 1 bert做分类任务


- 特别感谢苏神的博客和bert4keras项目，有关NLP的知识基本都是从苏神的博客中学来的，感谢苏神大佬


```python
import os
os.environ["TF_KERAS"] = "1"
```


```python
from bert4keras.models import build_transformer_model
from bert4keras.backend import  K

import keras
from keras.layers import Dense
from keras.layers import Input, Lambda
floatx = K.floatx()

```python
config_path = '/Users/coming/bert_model/chinese_L-12_H-768_A-12/bert_config.json'
checkpoint_path = '/Users/coming/bert_model/chinese_L-12_H-768_A-12/bert_model.ckpt'
dict_path = '/Users/coming/bert_model/chinese_L-12_H-768_A-12/vocab.txt',
```


```python
bert = build_transformer_model(
    config_path=config_path,
    checkpoint_path=checkpoint_path,
    return_keras_model=False,
    model='bert',
#     with_mlm='linear'
)
```


```python
shared_layer_output = Lambda(lambda x: x[:, 0], name='CLS-token')(bert.output)
```


```python
output = Dense(
    units=2,
    activation='softmax',
    kernel_initializer=bert.initializer,
    name='dense_output'
)(shared_layer_output)

model = keras.models.Model(bert.input, output)
```


```python
from keras.utils import plot_model

# plot_model(model, show_shapes=True)
```

![](./image/bert_model.png)


## 2 参数量计算

```python
model.summary()
```

    Model: "model_4"
    __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to
    ==================================================================================================
    Input-Token (InputLayer)        [(None, None)]       0
    __________________________________________________________________________________________________
    Input-Segment (InputLayer)      [(None, None)]       0
    __________________________________________________________________________________________________
    Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]
    __________________________________________________________________________________________________
    Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]
    __________________________________________________________________________________________________
    Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]
                                                                     Embedding-Segment[0][0]
    __________________________________________________________________________________________________
    Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]
    __________________________________________________________________________________________________
    Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]
    __________________________________________________________________________________________________
    Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]
    __________________________________________________________________________________________________
    Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]
                                                                     Embedding-Dropout[0][0]
                                                                     Embedding-Dropout[0][0]
    __________________________________________________________________________________________________
    Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]
                                                                     Transformer-0-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
                                                                     Transformer-0-FeedForward-Dropout
    __________________________________________________________________________________________________
    Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][
    __________________________________________________________________________________________________
    Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]
                                                                     Transformer-0-FeedForward-Norm[0]
                                                                     Transformer-0-FeedForward-Norm[0]
    __________________________________________________________________________________________________
    Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]
                                                                     Transformer-1-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
                                                                     Transformer-1-FeedForward-Dropout
    __________________________________________________________________________________________________
    Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][
    __________________________________________________________________________________________________
    Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]
                                                                     Transformer-1-FeedForward-Norm[0]
                                                                     Transformer-1-FeedForward-Norm[0]
    __________________________________________________________________________________________________
    Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]
                                                                     Transformer-2-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
                                                                     Transformer-2-FeedForward-Dropout
    __________________________________________________________________________________________________
    Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][
    __________________________________________________________________________________________________
    Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]
                                                                     Transformer-2-FeedForward-Norm[0]
                                                                     Transformer-2-FeedForward-Norm[0]
    __________________________________________________________________________________________________
    Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]
                                                                     Transformer-3-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
                                                                     Transformer-3-FeedForward-Dropout
    __________________________________________________________________________________________________
    Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][
    __________________________________________________________________________________________________
    Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]
                                                                     Transformer-3-FeedForward-Norm[0]
                                                                     Transformer-3-FeedForward-Norm[0]
    __________________________________________________________________________________________________
    Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]
                                                                     Transformer-4-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
                                                                     Transformer-4-FeedForward-Dropout
    __________________________________________________________________________________________________
    Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][
    __________________________________________________________________________________________________
    Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]
                                                                     Transformer-4-FeedForward-Norm[0]
                                                                     Transformer-4-FeedForward-Norm[0]
    __________________________________________________________________________________________________
    Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]
                                                                     Transformer-5-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
                                                                     Transformer-5-FeedForward-Dropout
    __________________________________________________________________________________________________
    Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][
    __________________________________________________________________________________________________
    Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]
                                                                     Transformer-5-FeedForward-Norm[0]
                                                                     Transformer-5-FeedForward-Norm[0]
    __________________________________________________________________________________________________
    Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]
                                                                     Transformer-6-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent
                                                                     Transformer-6-FeedForward-Dropout
    __________________________________________________________________________________________________
    Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][
    __________________________________________________________________________________________________
    Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]
                                                                     Transformer-6-FeedForward-Norm[0]
                                                                     Transformer-6-FeedForward-Norm[0]
    __________________________________________________________________________________________________
    Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]
                                                                     Transformer-7-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent
                                                                     Transformer-7-FeedForward-Dropout
    __________________________________________________________________________________________________
    Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][
    __________________________________________________________________________________________________
    Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]
                                                                     Transformer-7-FeedForward-Norm[0]
                                                                     Transformer-7-FeedForward-Norm[0]
    __________________________________________________________________________________________________
    Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]
                                                                     Transformer-8-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent
                                                                     Transformer-8-FeedForward-Dropout
    __________________________________________________________________________________________________
    Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][
    __________________________________________________________________________________________________
    Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]
                                                                     Transformer-8-FeedForward-Norm[0]
                                                                     Transformer-8-FeedForward-Norm[0]
    __________________________________________________________________________________________________
    Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]
                                                                     Transformer-9-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent
    __________________________________________________________________________________________________
    Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent
                                                                     Transformer-9-FeedForward-Dropout
    __________________________________________________________________________________________________
    Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][
    __________________________________________________________________________________________________
    Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]
                                                                     Transformer-9-FeedForward-Norm[0]
                                                                     Transformer-9-FeedForward-Norm[0]
    __________________________________________________________________________________________________
    Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten
    __________________________________________________________________________________________________
    Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]
                                                                     Transformer-10-MultiHeadSelfAtten
    __________________________________________________________________________________________________
    Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten
    __________________________________________________________________________________________________
    Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten
    __________________________________________________________________________________________________
    Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten
                                                                     Transformer-10-FeedForward-Dropou
    __________________________________________________________________________________________________
    Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]
    __________________________________________________________________________________________________
    Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0
                                                                     Transformer-10-FeedForward-Norm[0
                                                                     Transformer-10-FeedForward-Norm[0
    __________________________________________________________________________________________________
    Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten
    __________________________________________________________________________________________________
    Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0
                                                                     Transformer-11-MultiHeadSelfAtten
    __________________________________________________________________________________________________
    Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten
    __________________________________________________________________________________________________
    Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten
    __________________________________________________________________________________________________
    Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0]
    __________________________________________________________________________________________________
    Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten
                                                                     Transformer-11-FeedForward-Dropou
    __________________________________________________________________________________________________
    Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]
    __________________________________________________________________________________________________
    CLS-token (Lambda)              (None, 768)          0           Transformer-11-FeedForward-Norm[0
    __________________________________________________________________________________________________
    dense_output (Dense)            (None, 2)            1538        CLS-token[0][0]
    ==================================================================================================
    Total params: 101,678,594
    Trainable params: 101,678,594
    Non-trainable params: 0
    __________________________________________________________________________________________________


bert 的参数配置

```
{
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}
```

#### 2.1.1 考虑三种不同的embedding：

1. Token：tokenizer中一共涉及21128个字/词(vocab_size=21128)，参数量为21128∗768=16226304

2. Segment：一共有两种segment(type_vocab_size=2)，参数量为2∗768=1536

3. Position：序列最长为512(max_position_embeddings=512)，参数量为512∗768=393216

三种embedding相加之后还要再做一次layer normalization，每个normalization用到两个参数（均值和方差），768维的向量做normalization需要的参数量为2∗768=1536


#### 2.1.2 self-attention sublayer

embedding层的hidden_size=768，num_attention_heads=12，Q/K/V输出的维度为768/12=64：

1. Q、K、V的Linear层的参数量为(768∗64+64)∗3∗12=1771776

2. Concat之后到最终Output的Linear层的参数量为64∗12∗768+768=590592

3. 合计参数量为1771776+590592=2362368


#### 2.1.3 feed-forward sublayer

对FFN，bert-base的intermediate_size=3072，FFN层包含两个线性变换，对应的参数为(768∗3072+3072)+(3072∗768+768)=4722432


#### 2.1.4 layer-normalization

self-attention sublayer和feed-forward sublayer都用到了layer normalization，对应的参数量都是2∗768=1536

```python

```
