{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jieba\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_path = \"金庸小说精校版/\"\n",
    "data_path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1903\n",
      "['乘势', '乘机', '乘胜', '乘虚', '乘隙', '九', '也', '也好', '也就是说', '也是', '也罢', '了', '了解', '争取', '二', '二来', '二话不说', '二话没说', '于', '于是']\n"
     ]
    }
   ],
   "source": [
    "# 加载停用词表\n",
    "stop_words_file = open(data_path + \"stop_words.txt\", 'r',encoding=\"gbk\",)\n",
    "stop_words = list()\n",
    "for line in stop_words_file.readlines():\n",
    "    line = line.strip()   # 去掉每行末尾的换行符\n",
    "    stop_words.append(line)\n",
    "stop_words_file.close()\n",
    "print(len(stop_words))\n",
    "print(stop_words[300:320])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分词前在词库中加入人物名称、武功名称、门派名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/d9/1hp8c1n16xq2gypxpzgt_9m40000gn/T/jieba.cache\n",
      "Loading model cost 0.608 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1237\n"
     ]
    }
   ],
   "source": [
    "# 导入金庸小说人物\n",
    "people_names_file = open(data_path + \"金庸小说全人物.txt\", 'r',encoding=\"gbk\",)\n",
    "people_names = list()\n",
    "for line in people_names_file.readlines():\n",
    "    line = line.strip()   # 去掉每行末尾的换行符\n",
    "    jieba.add_word(line)\n",
    "    people_names.append(line)\n",
    "stop_words_file.close()\n",
    "print(len(people_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n"
     ]
    }
   ],
   "source": [
    "# 导入金庸小说武功\n",
    "kungfu_names_file = open(data_path + \"金庸小说全武功.txt\", 'r',encoding=\"gbk\",)\n",
    "kungfu_names = list()\n",
    "for line in kungfu_names_file.readlines():\n",
    "    line = line.strip()   # 去掉每行末尾的换行符\n",
    "    jieba.add_word(line)\n",
    "    kungfu_names.append(line)\n",
    "stop_words_file.close()\n",
    "print(len(kungfu_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "# 导入金庸小说门派\n",
    "sect_names_file = open(data_path + \"金庸小说全门派.txt\", 'r',encoding=\"gbk\",)\n",
    "sect_names = list()\n",
    "for line in sect_names_file.readlines():\n",
    "    line = line.strip()   # 去掉每行末尾的换行符\n",
    "    jieba.add_word(line)\n",
    "    sect_names.append(line)\n",
    "stop_words_file.close()\n",
    "print(len(sect_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_names = list(os.listdir(novel_path))\n",
    "novel_names = [i for i in novel_names if i.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['侠客行.txt',\n",
       " '射雕英雄传.txt',\n",
       " '鹿鼎记.txt',\n",
       " '越女剑.txt',\n",
       " '雪山飞狐.txt',\n",
       " '连城诀.txt',\n",
       " '飞狐外传.txt',\n",
       " '神雕侠侣.txt',\n",
       " '鸳鸯刀.txt',\n",
       " '天龙八部.txt',\n",
       " '碧血剑.txt',\n",
       " '白马啸西风.txt',\n",
       " '笑傲江湖.txt',\n",
       " '倚天屠龙记.txt',\n",
       " '书剑恩仇录.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.25 µs\n",
      "Waiting for 侠客行.txt...Waiting for 越女剑.txt...Waiting for 射雕英雄传.txt...Waiting for 鹿鼎记.txt...\n",
      "\n",
      "\n",
      "\n",
      "越女剑.txt finished，with 197 Row\n",
      "Waiting for 雪山飞狐.txt...\n",
      "雪山飞狐.txt finished，with 1097 Row\n",
      "Waiting for 连城诀.txt...\n",
      "侠客行.txt finished，with 3514 Row\n",
      "Waiting for 飞狐外传.txt...\n",
      "连城诀.txt finished，with 2207 Row\n",
      "Waiting for 神雕侠侣.txt...\n",
      "飞狐外传.txt finished，with 3777 Row\n",
      "Waiting for 鸳鸯刀.txt...\n",
      "鸳鸯刀.txt finished，with 213 Row\n",
      "Waiting for 天龙八部.txt...\n",
      "射雕英雄传.txt finished，with 7131 Row\n",
      "Waiting for 碧血剑.txt...\n",
      "鹿鼎记.txt finished，with 11159 Row\n",
      "Waiting for 白马啸西风.txt...\n",
      "白马啸西风.txt finished，with 597 Row\n",
      "Waiting for 笑傲江湖.txt...\n",
      "神雕侠侣.txt finished，with 6999 Row\n",
      "Waiting for 倚天屠龙记.txt...\n",
      "碧血剑.txt finished，with 3786 Row\n",
      "Waiting for 书剑恩仇录.txt...\n",
      "书剑恩仇录.txt finished，with 3561 Row\n",
      "天龙八部.txt finished，with 10948 Row\n",
      "笑傲江湖.txt finished，with 8551 Row\n",
      "倚天屠龙记.txt finished，with 7919 Row\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def f(novel_name):\n",
    "    tmp = []\n",
    "    novel = open(novel_path + novel_name, 'r', encoding='utf-8-sig')\n",
    "    print(\"Waiting for {}...\".format(novel_name))\n",
    "    line = novel.readline()\n",
    "    while line:\n",
    "        line_1 = line.strip()\n",
    "        outstr = ''\n",
    "        line_seg = jieba.cut(line_1, cut_all=False)\n",
    "        for word in line_seg:  \n",
    "            if word not in stop_words:\n",
    "                if word != '\\t':\n",
    "                    if word[:2] in people_names:\n",
    "                        word = word[:2]\n",
    "                    outstr += word \n",
    "                    outstr += \" \"\n",
    "        if len(str(outstr.strip())) != 0:\n",
    "            tmp.append(str(outstr.strip()).split())\n",
    "        line = novel.readline()\n",
    "    print(\"{} finished，with {} Row\".format(novel_name, (len(tmp))))\n",
    "    return tmp\n",
    "\n",
    "pool = Pool(4)\n",
    "b = pool.map(f, novel_names)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_novel = []\n",
    "for i in b:\n",
    "    seg_novel.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# seg_novel = []\n",
    "# for novel_name in novel_names:\n",
    "#     novel = open(novel_path + novel_name, 'r', encoding='utf-8-sig')\n",
    "#     print(\"Waiting for {}...\".format(novel_name))\n",
    "#     line = novel.readline()\n",
    "#     forward_rows = len(seg_novel)\n",
    "#     while line:\n",
    "#         line_1 = line.strip()\n",
    "#         outstr = ''\n",
    "#         line_seg = jieba.cut(line_1, cut_all=False)\n",
    "#         for word in line_seg:  \n",
    "#             if word not in stop_words:\n",
    "#                 if word != '\\t':\n",
    "#                     if word[:2] in people_names:\n",
    "#                         word = word[:2]\n",
    "#                     outstr += word \n",
    "#                     outstr += \" \"\n",
    "#         if len(str(outstr.strip())) != 0:\n",
    "#             seg_novel.append(str(outstr.strip()).split())\n",
    "#         line = novel.readline()\n",
    "#     print(\"{} finished，with {} Row\".format(novel_name, (len(seg_novel) - forward_rows)))\n",
    "#     print(\"-\" * 40)\n",
    "# print(\"-\" * 40)\n",
    "# print(\"-\" * 40)\n",
    "# print(\"All finished，with {} Row\".format(len(seg_novel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['甄志丙', '定神', '暗想', '两个', '长辈', '合斗', '少年', '那成', '样子', '眼见', '胜算', '已然', '在握', '记挂', '小龙女', '安危', '喝道', '杨过', '扶', '姑姑', '回去', '瞎', '缠', '杨过', '姑姑', '恨', '胡说八道', '非', '杀', '甄志丙', '呼', '一掌', '左手', '剑震', '歪', '左跃开', '三步', '住', '杨过', '想', '逃', '甄志丙', '杨过', '想', '杀', '两个', '千难万难', '好教', '姑姑', '放心', '今日', '事', '我姓', '甄', '吐露', '半句', '自刎', '相谢', '食言', '左掌', '向天', '甄志丙', '死', '惨', '不堪', '言', '死后', '身入', '十八层', '地狱', '来世', '做', '狗', '做', '猪', '永为', '畜生']\n",
      "['杨过', '一呆', '之下', '听', '诚恳', '已知', '誓言', '出自', '真心', '喝道', '姓', '甄', '做', '猪', '做', '狗', '倒', '相配', '向前', '踏上', '两步', '蓦地', '里挺剑', '背后', '刺', '直指', '赵志敬', '胸口']\n",
      "['一招', '木兰', '回射', '阴毒', '无比', '赵志敬', '正自', '全神', '倾听', '二人', '说话', '料到', '忽施', '偷击', '惊觉', '剑尖', '刺', '小腹', '赵志敬', '只感', '微微', '一痛', '气运', '丹田', '小腹', '斗然间', '缩', '半尺', '疾起', '右腿', '杨过', '手中', '长剑', '踢飞', '杨过', '右腿', '缩回', '伸', '指向', '膝弯', '里点', '正中', '穴道', '赵志敬', '逃脱', '性命', '再也', '站立', '不住', '右腿', '跪倒', '杨过', '面前']\n",
      "['杨过', '手接', '住', '空中', '落下', '长剑', '指在', '赵志敬', '咽喉', '拜你为师', '磕过', '八个', '头', '现下', '非', '我师', '八个', '头快', '磕', '回来', '赵志敬', '气得', '几欲', '晕', '脸皮', '紫胀', '几成', '黑色', '杨过', '手上', '稍稍', '用力', '剑尖', '陷入', '喉头', '肉里', '赵志敬', '骂', '杀', '杀', '杨过', '剑', '正要', '刺去', '忽', '听', '小龙女', '背后', '过儿', '师父', '杀', '立誓', '不说', '今日', '事', '饶', '罢']\n",
      "['杨过', '小龙女', '言', '奉若神明', '听', '发个', '誓来', '赵志敬', '气', '性命', '要紧', '发', '誓', '杨过', '非发个', '毒誓', '赵志敬', '今日', '事', '四人', '第五个', '说起', '教', '身败名裂', '逐出', '师门', '武林', '同道', '不齿', '终于', '不得好死']\n",
      "['小龙女', '杨过', '不谙世事', '只道', '发了', '毒誓', '甄志丙', '听', '誓言', '之中', '另藏', '别意', '待要', '提醒', '杨过', '觉', '不便', '明助', '外人', '只见', '杨过', '抱', '小龙女', '脚步', '迅捷', '转过', '山腰']\n",
      "['杨过', '抱', '小龙女', '回到', '古墓', '放', '上寒玉', '床', '小龙女', '叹', '身受', '重伤', '寒气', '相抗', '杨过', '一声', '心中', '愈惊', '暗想', '姑姑', '受伤', '之重', '抱', '邻室', '卧房', '小龙女', '刚一', '卧倒', '一声', '喷出', '大口', '鲜血', '杨过', '赤裸', '上身', '喷得', '胸', '血', '喘息', '几下', '喷', '一口', '血', '杨过', '手足无措', '流泪']\n",
      "['小龙女', '淡淡', '一笑', '血', '喷', '完', '喷', '伤心', '杨过', '姑姑', '你别', '死', '小龙女', '怕死', '杨过', '愕然', '小龙女', '死', '自然', '先', '杀', '这话', '两年', '多前', '杨过', '早就', '忘', '想不到', '重', '提起', '小龙女', '满脸', '讶异', '之色', '杀', '死', '怎有', '脸', '孙婆婆', '独个儿', '世上', '照料', '杨过', '中', '惶乱', '不知']\n",
      "['小龙女', '吐血', '神情', '甚为', '镇定', '浑若', '无事', '杨过', '灵机一动', '奔', '舀', '大碗', '玉', '蜂蜜', '浆来', '喝', '这蜜浆', '疗伤', '果有', '神效', '不多时', '终于', '吐血', '躺', '床上', '沉沉', '睡', '杨过', '中略定', '惊', '疲', '交集', '再也', '支持不住', '坐在', '地下', '倚', '墙', '睡着']\n",
      "['不知', '忽觉', '咽喉', '一凉', '惊醒', '古墓', '中住', '多年', '小龙女', '般', '黑暗', '中视', '物', '有如', '白昼', '墓', '中来', '不须', '秉烛', '点灯', '睁开眼', '小龙女', '坐在', '床沿', '手执', '长剑', '剑尖', '指在', '喉头', '一惊', '之下', '姑姑']\n"
     ]
    }
   ],
   "source": [
    "for line in seg_novel[30000:30010]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models as w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = w2v.Word2Vec(sentences=seg_novel, size=200, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 寻找相似关系\n",
    "def find_relation(a, b, c):\n",
    "    d, _ = model.most_similar(positive=[c, b], negative=[a])[0]\n",
    "    print (c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天地会 顾炎武\n"
     ]
    }
   ],
   "source": [
    "find_relation(\"武当派\",\"张三丰\",\"天地会\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('赵敏', 0.638274073600769),\n",
       " ('周芷若', 0.588302493095398),\n",
       " ('杨逍', 0.5207088589668274),\n",
       " ('小昭', 0.4938661456108093),\n",
       " ('韦一笑', 0.48968780040740967),\n",
       " ('范遥', 0.4888066053390503),\n",
       " ('虚竹', 0.48539090156555176),\n",
       " ('蛛儿', 0.48395872116088867),\n",
       " ('游坦之', 0.46333184838294983),\n",
       " ('殷天正', 0.45917046070098877)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"张无忌\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(data_path + 'all_skip_gram.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = w2v.Word2Vec.load(data_path + 'all_skip_gram.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5883025\n",
      "0.63827395\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('张无忌', '周芷若'))\n",
    "print(model.similarity('张无忌', '赵敏'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('施琅', 0.6210408210754395), ('索额图', 0.6192328929901123), ('康熙', 0.6170916557312012), ('费要多罗', 0.5796799063682556), ('苏菲亚', 0.5737735629081726), ('多隆', 0.562697172164917), ('佟国纲', 0.5488145351409912), ('小桂子', 0.5483344793319702), ('吴三桂', 0.5413446426391602), ('吴之荣', 0.5345876216888428)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(\"韦小宝\", topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('林朝英', 0.8638086915016174),\n",
       " ('神通', 0.8489284515380859),\n",
       " ('华山论剑', 0.8460357189178467),\n",
       " ('宝典', 0.8342050313949585),\n",
       " ('苦修', 0.8326935172080994),\n",
       " ('研习', 0.8323312997817993),\n",
       " ('创制', 0.8284924030303955),\n",
       " ('剑宗', 0.8257396221160889),\n",
       " ('北丐', 0.8161500692367554),\n",
       " ('窥', 0.8158167600631714)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"王重阳\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38065296\n",
      "0.49260202\n",
      "0.49033725\n",
      "0.43640834\n",
      "0.36252627\n",
      "0.3301066\n",
      "0.4234184\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('韦小宝', '阿珂'))\n",
    "print(model.similarity('韦小宝', '双儿'))\n",
    "print(model.similarity('韦小宝', '建宁公主'))\n",
    "print(model.similarity('韦小宝', '苏荃'))\n",
    "print(model.similarity('韦小宝', '沐剑屏'))\n",
    "print(model.similarity('韦小宝', '曾柔'))\n",
    "print(model.similarity('韦小宝', '方怡'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乔峰 阿朱\n"
     ]
    }
   ],
   "source": [
    "find_relation(\"杨过\",\"小龙女\",\"乔峰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf21",
   "language": "python",
   "name": "tf21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
